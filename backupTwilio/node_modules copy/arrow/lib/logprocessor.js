/**
 * This code is closed source and Confidential and Proprietary to
 * Appcelerator, Inc. All Rights Reserved.  This code MUST not be
 * modified, copied or otherwise redistributed without express
 * written permission of Appcelerator. This file is licensed as
 * part of the Appcelerator Platform and governed under the terms
 * of the Appcelerator license agreement.
 */
var fs = require('fs'),
	path = require('path'),
	async = require('async'),
	urllib = require('url'),
	zlib = require('zlib'),
	Logger = require('appc-logger'),
	config = path.join(process.cwd(), 'conf', 'deploy.json'),
	arrow,
	request = require('request'),
	timer,
	key,
	reqid,
	logserver;

// delay in ms before we attempt to send logs
const DELAY = 10000,
// time in ms for the log file to have been modified
	QUIET = 30000;

try {
	arrow = require('arrow');
}
catch (e) {
}

//TODO: right now, we send one log file at a time. we might consider
//batching them and sending all of them at once. the advantage of one per
//is that if we have a failure, we can quickly recover and re-send.

/**
 * restart our timer when we will attempt to send logs
 */
function startTimer() {
	console.log('startTimer called', DELAY);
	timer = setTimeout(sendLogs, DELAY);
}

/**
 * Calculates a SHA1 for the provided value.
 * @param value
 * @returns {*}
 */
function sha1(value) {
	var crypto = require('crypto'),
		shasum = crypto.createHash('sha1');
	shasum.update(value);
	return shasum.digest('hex');
}

/**
 * on startup we fetch our API key that we'll use to make subsequent requests with
 */
function fetchAPIKey() {
	var url = urllib.resolve(logserver, '/genkey/' +
		encodeURIComponent(process.env.serverId || 'local') + '/' +
		encodeURIComponent(process.env.appid || 'local') + '/' +
		encodeURIComponent(process.env.NODE_ACS_URL || 'local') + '/' +
		encodeURIComponent('' + config.org_id) + '/' +
		encodeURIComponent(config.username) + '/' +
		encodeURIComponent(config.name) + '/' +
		encodeURIComponent(config.version)
	);
	request(url, function (err, resp, body) {
		console.log('fetchAPIKey body=', body, 'url=', url, 'error=', err, 'headers=', resp.headers);
		if (body && typeof(body) === 'string') {
			body = JSON.parse(body);
		}
		if (body && body.success && body.key) {
			key = body[body.key];
			reqid = sha1(new Buffer(process.env.serverId + ':' + process.env.appid).toString('base64'));
			process.nextTick(sendLogs);
		}
	});
}

/**
 * send a specific log file
 */
function sendLog(fn, callback) {
	if (!fs.existsSync(fn)) {
		return callback('not found: ' + fn);
	}
	var url = urllib.resolve(logserver, '/logfile'),
		data = {
			apikey: key,
			log: fs.readFileSync(fn).toString(),
			metadata: fs.existsSync(fn + '.metadata') && fs.readFileSync(fn + '.metadata').toString() || '{}'
		},
		opts = {
			url: url,
			method: 'post',
			headers: {
				apikey: key,
				apirequestid: reqid,
				'Content-Encoding': 'gzip',
				'Content-Type': 'application/json; charset=UTF-8'
			}
		};
	console.log('sendLog', opts);
	// gzip the data and send it
	zlib.gzip(JSON.stringify(data), function (err, buffer) {
		err && console.error('error', err);
		if (err) { return callback(err); }
		var req = request(opts, callback);
		req.on('error', callback);
		req.end(buffer);
	});
}

/**
 * queue a delayed send
 */
function queueSendLog(fn, callback) {
	// randomize a delay so we don't send too fast from 0 to 1 sec
	var delay = Math.floor(Math.random() * 1000);
	console.log('queueSendLog filename=', fn, 'delay=', delay);
	setTimeout(function () {
		sendLog(fn, callback);
	}, delay);
}

/**
 * attempt to send logs
 */
function sendLogs() {
	var globalArrow = arrow && arrow.getGlobal(),
		logdir = Logger.arrowCloudLogDir || path.join((globalArrow && globalArrow.config.dir) || process.cwd(), 'logs');
	console.log('sendLogs', logserver);
	if (fs.existsSync(logdir) && logserver) {
		fs.readdir(logdir, function (err, files) {
			if (files && files.length) {
				async.eachSeries(files, function (fn, cb) {
					if (/^request-(.*)\.log$/.test(fn)) {
						fn = path.join(logdir, fn);
						if (fs.existsSync(fn)) {
							var ts = Date.now() - fs.statSync(fn).mtime.getTime();
							if (ts > QUIET) {
								// queue the send
								return queueSendLog(fn, function (err) {
									if (!err) {
										async.each([fn, fn + '.metadata'], function (f, c) {
											if (fs.existsSync(f)) {
												console.log('removing', f);
												fs.unlink(f, c);
											} else {
												console.log('skipping', f);
												c();
											}
										}, cb);
									} else {
										console.log('sendLog error', err);
										// process it again later?
										cb();
									}
								});
							}
						}
					}
					cb();
				}, startTimer);
			} else {
				startTimer();
			}
		});
	} else {
		startTimer();
	}
}

// stop processing when interrupted
process.on('SIGINT', function () {
	console.log('SIGINT');
	clearTimeout(timer);
	process.exit();
});

process.on('exit', function (code) {
	console.log('exit=' + code);
	clearTimeout(timer);
	process.exit(code);
});

// config doesn't exist, just exit with special exit code
if (!fs.existsSync(config)) {
	console.log(config + ' doesn\'t exist');
	process.exit(2);
} else {
	config = JSON.parse(fs.readFileSync(config));
	logserver = config.logserver;
	if (logserver) {
		console.log('scheduling log processor');
		setTimeout(fetchAPIKey, 5000);
	} else {
		process.exit(2);
	}
}
